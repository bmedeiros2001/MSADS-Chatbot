{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0m1dQLK6rp9",
        "outputId": "0f111427-a533-4fe6-ff34-689428873a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "HLfpwV9sA1Zy"
      },
      "outputs": [],
      "source": [
        "def install_if_missing(package, import_name=None):\n",
        "    import importlib\n",
        "    try:\n",
        "        importlib.import_module(import_name or package)\n",
        "    except ImportError:\n",
        "        import subprocess\n",
        "        subprocess.check_call([\"pip\", \"install\", package])\n",
        "\n",
        "# Install packages as needed\n",
        "install_if_missing(\"pandas\")\n",
        "install_if_missing(\"numpy\")\n",
        "install_if_missing(\"langchain\")\n",
        "install_if_missing(\"langchain-community\")\n",
        "install_if_missing(\"langchain-chroma\")\n",
        "install_if_missing(\"langchain-openai\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.schema import Document\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
        "from langchain import hub\n",
        "\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "BOLD = \"\\033[1m\"\n",
        "END   = \"\\033[0m\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utuFOrFMP5_a",
        "outputId": "220c14cd-b324-4a2e-ad42-e6e5d8288b38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key:··········\n",
            "Enter your LangSmith API key:··········\n",
            "Enter your HuggingFace API token:··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "OPENAI_KEY = getpass(\"Enter your OpenAI API key:\")\n",
        "LANGCHAIN_API_KEY = getpass(\"Enter your LangSmith API key:\")\n",
        "HUGGINGFACEHUB_API_TOKEN = getpass(\"Enter your HuggingFace API token:\")\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdwJkX4TDOU-"
      },
      "source": [
        "## Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vQpEsYzA3n2",
        "outputId": "d7b31bd5-3aa5-4cf1-ba75-0f95a98f689d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 12 document(s):\n",
            " • 000_ms-in-applied-data-science.md\n",
            " • 001_in-person-program.md\n",
            " • 002_capstone-projects.md\n",
            " • 003_course-progressions.md\n",
            " • 004_how-to-apply.md\n",
            " • 005_events-deadlines.md\n",
            " • 006_our-students.md\n",
            " • 007_instructors-staff.md\n",
            " • 008_faqs.md\n",
            " • 009_career-outcomes.md\n",
            " • 010_online-program.md\n",
            " • 011_tuition-fees-aid.md\n"
          ]
        }
      ],
      "source": [
        "def load_md_docs(base_folder: str, single_mode: bool) -> list[Document]:\n",
        "    \"\"\"\n",
        "    TRUE: load only pages/012_%20.md\n",
        "    FALSE : load all .md under pages except 012_%20.md\n",
        "    \"\"\"\n",
        "\n",
        "    # the one file to isolate\n",
        "    special = os.path.join(base_folder, \"012_%20.md\")\n",
        "\n",
        "    if single_mode:\n",
        "        paths = [special]\n",
        "    else:\n",
        "        paths = [os.path.join(base_folder, fn) for fn in os.listdir(base_folder) if fn.endswith(\".md\") and os.path.join(base_folder, fn) != special]\n",
        "\n",
        "    docs = []\n",
        "    for path in paths:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "        docs.append(Document(page_content=text,metadata={\"source\": os.path.basename(path)}))\n",
        "    return docs\n",
        "\n",
        "# ─── USAGE ─────────────────────────────────────────────────────────────\n",
        "base_folder = \"/content/drive/MyDrive/Gen AI Shared/msads_pages/pages\"\n",
        "\n",
        "# Toggle this:\n",
        "SINGLE_MODE = False\n",
        "docs = load_md_docs(base_folder, SINGLE_MODE)\n",
        "\n",
        "print(f\"Loaded {len(docs)} document(s):\")\n",
        "for d in docs:\n",
        "    print(\" •\", d.metadata[\"source\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTTjfMhCEqVx"
      },
      "source": [
        "## Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWckcVC7DVl1",
        "outputId": "fb7c11ae-f1cf-4eef-8fc2-08317aeee0df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Using Mode = ALL except 012_%20.md\n",
            " • Documents loaded  : 12\n",
            " • Total chunks      : 331\n",
            " • Avg chunk length  : 708 chars\n",
            " • Chunk length range: 41–998 chars\n",
            "\u001b[1m\n",
            "Total number of chunks after splitting\u001b[0m: 331\n",
            "\u001b[1mCharacter count on first chunk\u001b[0m: 885\n",
            "\u001b[1mFirst chunk URL\u001b[0m: https://datascience.uchicago.edu/education/masters-programs/ms-in-applied-data-science/\n",
            "\u001b[1mSmallest chunk size\u001b[0m: 41 characters\n",
            "\u001b[1mLargest chunk size\u001b[0m: 998 characters\n"
          ]
        }
      ],
      "source": [
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    add_start_index=True\n",
        ")\n",
        "\n",
        "def add_url_to_chunks(docs, splitter):\n",
        "    all_chunks = []\n",
        "    for doc in docs:\n",
        "        # Extract URL from document\n",
        "        url = \"Unknown\"\n",
        "        for line in doc.page_content.split('\\n')[:5]:\n",
        "            if line.startswith(\"# Source: \"):\n",
        "                url = line.replace(\"# Source: \", \"\").strip()\n",
        "                break\n",
        "\n",
        "        # Split the document\n",
        "        chunks = splitter.split_documents([doc])\n",
        "\n",
        "        # Add URL to each chunk's metadata\n",
        "        for chunk in chunks:\n",
        "            chunk.metadata['url'] = url\n",
        "\n",
        "        all_chunks.extend(chunks)\n",
        "\n",
        "    return all_chunks\n",
        "\n",
        "# Use the SINGLE_MODE you set earlier (respects your toggle choice)\n",
        "docs = load_md_docs(base_folder, SINGLE_MODE)\n",
        "all_splits = add_url_to_chunks(docs, splitter)\n",
        "\n",
        "sizes = [len(c.page_content) for c in all_splits]\n",
        "print(f\"\\nUsing Mode = {'ONLY 012_%20.md' if SINGLE_MODE else 'ALL except 012_%20.md'}\")\n",
        "print(f\" • Documents loaded  : {len(docs)}\")\n",
        "print(f\" • Total chunks      : {len(all_splits)}\")\n",
        "print(f\" • Avg chunk length  : {sum(sizes)/len(sizes):.0f} chars\")\n",
        "print(f\" • Chunk length range: {min(sizes)}–{max(sizes)} chars\")\n",
        "\n",
        "print(f\"{BOLD}\\nTotal number of chunks after splitting{END}: {len(all_splits)}\")\n",
        "print(f\"{BOLD}Character count on first chunk{END}: {len(all_splits[0].page_content)}\")\n",
        "print(f\"{BOLD}First chunk URL{END}: {all_splits[0].metadata.get('url', 'No URL')}\")\n",
        "print(f\"{BOLD}Smallest chunk size{END}: {min(sizes)} characters\")\n",
        "print(f\"{BOLD}Largest chunk size{END}: {max(sizes)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CIZr0rdEpD6"
      },
      "source": [
        "## Indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbt1iJo5BjOe",
        "outputId": "77244a1a-8dae-41d3-ed93-9531c4825b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created new vectorstore with 331 documents\n"
          ]
        }
      ],
      "source": [
        "# Embed model + upload into DB\n",
        "\n",
        "persist_directory = \"/content/drive/MyDrive/Gen AI Shared/msads_vectorstore_FINAL\"\n",
        "\n",
        "# Recreate the vectorstore\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=all_splits,\n",
        "    embedding=embedding_model,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "print(f\"Created new vectorstore with {vectorstore._collection.count()} documents\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "6Dz6lEtB_wh9",
        "outputId": "0a04678b-0322-41c0-c559-207ca2fd242d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Created backup: /content/msads_vectorstore_backup.zip\n",
            "Zip file size: 1.5 MB\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_9c7b2c9d-7c28-401c-9bfa-842d9dea04f0\", \"msads_vectorstore_backup.zip\", 1615420)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Create zip file\n",
        "source_path = \"/content/drive/MyDrive/Gen AI Shared/msads_vectorstore_FINAL\"\n",
        "zip_path = \"/content/msads_vectorstore_backup\"\n",
        "\n",
        "shutil.make_archive(zip_path, 'zip', source_path)\n",
        "print(f\"✅ Created backup: {zip_path}.zip\")\n",
        "\n",
        "# Check zip file size\n",
        "zip_size = os.path.getsize(f\"{zip_path}.zip\")\n",
        "print(f\"Zip file size: {zip_size / (1024*1024):.1f} MB\")\n",
        "\n",
        "# download from colab\n",
        "from google.colab import files\n",
        "files.download('msads_vectorstore_backup.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "4c8kONoAF9Iy"
      },
      "outputs": [],
      "source": [
        "################# RUN ON COMMAND\n",
        "\n",
        "\n",
        "# # Remove the old broken vectorstore first\n",
        "# rm -rf msads_vectorstore\n",
        "\n",
        "# # Move the new working one\n",
        "# mv msads_vectorstore_backup msads_vectorstore\n",
        "\n",
        "\n",
        "# python -c \"\n",
        "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "# from langchain_chroma import Chroma\n",
        "\n",
        "# print('Loading embedding model...')\n",
        "# embedding_model = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# print('Loading vectorstore...')\n",
        "# vectorstore = Chroma(persist_directory='msads_vectorstore', embedding_function=embedding_model)\n",
        "\n",
        "# print(f'✅ Loaded {vectorstore._collection.count()} documents')\n",
        "\n",
        "# print('Testing retrieval...')\n",
        "# results = vectorstore.similarity_search('portfolio', k=2)\n",
        "# print(f'✅ Retrieved {len(results)} documents')\n",
        "# for i, doc in enumerate(results):\n",
        "#     print(f'  Doc {i+1}: {doc.metadata.get(\\\"source\\\", \\\"Unknown\\\")}')\n",
        "# \"\n",
        "\n",
        "# streamlit run streamlit_app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAhg02voGR1n"
      },
      "source": [
        "## Retrieve & Generate - Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ztsHCmZUYd-k"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "_ysAh0oGE3Dm"
      },
      "outputs": [],
      "source": [
        "test_queries = [\n",
        "    \"What is tuition cost for the program?\",\n",
        "    \"What scholarships are available for the program?\",\n",
        "    \"What are the minimum scores for the TOEFL and IELTS English Language Requirement?\",\n",
        "    \"Is there an application fee waiver?\",\n",
        "    \"What are the deadlines for the in-person program?\",\n",
        "    \"How long will it take for me to receive a decision on my application?\",\n",
        "    \"Can I set up an advising appointment with the enrollment management team?\",\n",
        "    \"Where can I mail my official transcripts?\",\n",
        "    \"Does the Master’s in Applied Data Science Online program provide visa sponsorship?\",\n",
        "    \"How do I apply to the MBA/MS program?\",\n",
        "    \"Is the MS in Applied Data Science program STEM/OPT eligible?\",\n",
        "    \"How many courses must you complete to earn UChicago’s Master’s in Applied Data Science?\",\n",
        "\n",
        "\n",
        "    # ADDITIONAL QUESTIONS\n",
        "    \"What are the career outcomes for both internships and full-time roles\"\n",
        "    \"for this program (based on previous student's outcomes)? Where did you get this information?\",\n",
        "    \"What are some of professors in this program?\",\n",
        "    \"Who is this professor named Utku?\",\n",
        "    \"Are transcripts required? If yes, which one?\",\n",
        "    \"Where do i send my e-transcript?\",\n",
        "    \"Do I need to send a Portfolio?\"\n",
        "\n",
        "]\n",
        "\n",
        "# include LLM to return the source\n",
        "'''def format_docs(docs):\n",
        "    formatted = []\n",
        "    for i, doc in enumerate(docs):\n",
        "        url = doc.metadata.get(\"url\", \"Unknown\")\n",
        "        formatted.append(f\"[Source {i+1} - {url}]:\\n{doc.page_content.strip()}\")\n",
        "    return \"\\n\\n\".join(formatted)'''\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    api_key=OPENAI_KEY,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":10})\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)\n",
        "\n",
        "# get RAG prompt template\n",
        "'''prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Answer the question based only on the provided context.\n",
        "\n",
        "IMPORTANT: Always cite your sources using [source_name] notation from the context.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer with citations\n",
        "\"\"\")'''\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# create RAG chain\n",
        "'''rag_chain = (\n",
        "    {\"context\": retriever | format_docs,\n",
        "     \"question\": RunnablePassthrough()}\n",
        "     | prompt\n",
        "     | llm\n",
        "     | StrOutputParser()\n",
        ")'''\n",
        "\n",
        "# RAG chain with sources\n",
        "rag_chain_with_sources = RunnableParallel(\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        ").assign(\n",
        "    answer=prompt | llm | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTbsPVsORe0A",
        "outputId": "c0d35ea8-8a10-4b61-b9d2-908c9eb9767f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST RESULTS:\n",
            "\n",
            "QUERY 1: What is tuition cost for the program?\n",
            "ANSWER:\n",
            "The tuition for the MS in Applied Data Science program is $6,384 per course, with a total tuition cost of $76,608. There is also a non-refundable program enrollment deposit of $1,500, which is credited toward your first quarter’s tuition balance. Please note that tuition is expected to increase 3-7% per year.\n",
            "\n",
            "SOURCES:\n",
            "- 011_tuition-fees-aid.md\n",
            "- 001_in-person-program.md\n",
            "- 008_faqs.md\n",
            "- 004_how-to-apply.md\n",
            "- 003_course-progressions.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 2: What scholarships are available for the program?\n",
            "ANSWER:\n",
            "The MS in Applied Data Science program offers merit-based scholarships and partial tuition scholarships to top applicants. These scholarships do not require a separate application. Two specific scholarships mentioned are The Data Science Institute Scholarship and the MS in Applied Data Science Alumni Scholarship.\n",
            "\n",
            "SOURCES:\n",
            "- 011_tuition-fees-aid.md\n",
            "- 008_faqs.md\n",
            "- 007_instructors-staff.md\n",
            "- 002_capstone-projects.md\n",
            "- 004_how-to-apply.md\n",
            "- 001_in-person-program.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 3: What are the minimum scores for the TOEFL and IELTS English Language Requirement?\n",
            "ANSWER:\n",
            "The minimum TOEFL iBT score required for admission is 104 and the minimum IELTS score required is 7.\n",
            "\n",
            "SOURCES:\n",
            "- 008_faqs.md\n",
            "- 004_how-to-apply.md\n",
            "- 001_in-person-program.md\n",
            "- 003_course-progressions.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 4: Is there an application fee waiver?\n",
            "ANSWER:\n",
            "Yes, there is a possibility for an application fee waiver. For questions regarding an application fee waiver, you should refer to the Physical Sciences Division fee waiver policy on the University of Chicago's website.\n",
            "\n",
            "SOURCES:\n",
            "- 004_how-to-apply.md\n",
            "- 008_faqs.md\n",
            "- 011_tuition-fees-aid.md\n",
            "- 010_online-program.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 5: What are the deadlines for the in-person program?\n",
            "ANSWER:\n",
            "The first priority deadline for applications to the in-person program is November 6, 2025. The program admits full- and part-time students for entrance in the autumn quarter annually. Applications are typically released 1-2 months after the previous deadline.\n",
            "\n",
            "SOURCES:\n",
            "- 008_faqs.md\n",
            "- 005_events-deadlines.md\n",
            "- 010_online-program.md\n",
            "- 004_how-to-apply.md\n",
            "- 001_in-person-program.md\n",
            "- 003_course-progressions.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 6: How long will it take for me to receive a decision on my application?\n",
            "ANSWER:\n",
            "Typically, admissions decisions for the Master's in Applied Data Science program are released 1-2 months after each application deadline. However, it's important to note that your application must be complete in order to be reviewed and for an admissions decision to be made. If you finish your application before the deadline, you will not receive your decision early.\n",
            "\n",
            "SOURCES:\n",
            "- 008_faqs.md\n",
            "- 004_how-to-apply.md\n",
            "- 005_events-deadlines.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 7: Can I set up an advising appointment with the enrollment management team?\n",
            "ANSWER:\n",
            "Yes, you can set up an advising appointment with the enrollment management team. Both Jose Alvarado, the Associate Director of Enrollment Management, and Patrick Vonesh, the Senior Assistant Director of Enrollment Management, support prospective students throughout the admissions process. You can schedule an appointment through the university's application portal.\n",
            "\n",
            "SOURCES:\n",
            "- 007_instructors-staff.md\n",
            "- 004_how-to-apply.md\n",
            "- 001_in-person-program.md\n",
            "- 010_online-program.md\n",
            "- 008_faqs.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 8: Where can I mail my official transcripts?\n",
            "ANSWER:\n",
            "You can mail your official transcripts to the following address: The University of Chicago, Attention: MS in Applied Data Science Admissions, 455 N Cityfront Plaza Dr., Suite 950, Chicago, Illinois 60611. If your institution can send your documents electronically, you can have them sent to applieddatascience-admissions@uchicago.edu.\n",
            "\n",
            "SOURCES:\n",
            "- 008_faqs.md\n",
            "- 004_how-to-apply.md\n",
            "- 001_in-person-program.md\n",
            "- 011_tuition-fees-aid.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 9: Does the Master’s in Applied Data Science Online program provide visa sponsorship?\n",
            "ANSWER:\n",
            "No, the Master’s in Applied Data Science Online program does not provide visa sponsorship. Only the full-time, In-Person program is eligible for visa sponsorship. International students are welcome to apply to the online program, but it does not provide visa sponsorship.\n",
            "\n",
            "SOURCES:\n",
            "- 008_faqs.md\n",
            "- 004_how-to-apply.md\n",
            "- 011_tuition-fees-aid.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 10: How do I apply to the MBA/MS program?\n",
            "ANSWER:\n",
            "To apply to the MBA/MS program, you need to go through Booth’s centralized, joint-application process. Complete the Chicago Booth Full-Time MBA application and select the MBA/MS in Applied Data Science as your program of interest. There will be a supplement for the MBA/MS program within your Booth application that contains specific questions for the Applied Data Science program. This supplement, along with your full Booth application, will be reviewed by the Applied Data Science admissions team.\n",
            "\n",
            "SOURCES:\n",
            "- 004_how-to-apply.md\n",
            "- 000_ms-in-applied-data-science.md\n",
            "- 008_faqs.md\n",
            "- 003_course-progressions.md\n",
            "- 011_tuition-fees-aid.md\n",
            "- 007_instructors-staff.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 11: Is the MS in Applied Data Science program STEM/OPT eligible?\n",
            "ANSWER:\n",
            "Yes, the MS in Applied Data Science program is STEM/OPT eligible.\n",
            "\n",
            "SOURCES:\n",
            "- 001_in-person-program.md\n",
            "- 010_online-program.md\n",
            "- 007_instructors-staff.md\n",
            "- 008_faqs.md\n",
            "- 011_tuition-fees-aid.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 12: How many courses must you complete to earn UChicago’s Master’s in Applied Data Science?\n",
            "ANSWER:\n",
            "To earn UChicago’s Master’s in Applied Data Science, you must successfully complete 12 courses. These include 6 core courses, 4 elective courses, and 2 Capstone courses.\n",
            "\n",
            "SOURCES:\n",
            "- 010_online-program.md\n",
            "- 001_in-person-program.md\n",
            "- 008_faqs.md\n",
            "- 004_how-to-apply.md\n",
            "- 006_our-students.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 13: What are the career outcomes for both internships and full-time rolesfor this program (based on previous student's outcomes)? Where did you get this information?\n",
            "ANSWER:\n",
            "The career outcomes for students in the MS in Applied Data Science program at UChicago include roles as Data Scientist (most common), Senior Data Science Consultant, Business Intelligence (BI) Director, Data Visualization Manager, Data Analytics Engineer, and AI Solution Architect. Some students also secure internships, as evidenced by a student who pursued a summer internship at a digital marketing company. This information was obtained from the program's official webpages on the University of Chicago's website.\n",
            "\n",
            "SOURCES:\n",
            "- 010_online-program.md\n",
            "- 001_in-person-program.md\n",
            "- 003_course-progressions.md\n",
            "- 006_our-students.md\n",
            "- 008_faqs.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 14: What are some of professors in this program?\n",
            "ANSWER:\n",
            "Some of the professors in this program include Greg Green, PhD, who is the Program Director, Arnab Bose, PhD, who is an Associate Senior Instructional Professor and Program Director of MS in Applied Data Science Online Program, Francisco Azeredo, PhD, Anil D Chaturvedi, PhD, Nick Kadochnikov, Ming-Long Lam, PhD, Roger Moore, MBA, and Utku Pamuksuz, PhD, all of whom are Associate Clinical Professors.\n",
            "\n",
            "SOURCES:\n",
            "- 001_in-person-program.md\n",
            "- 007_instructors-staff.md\n",
            "- 003_course-progressions.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 15: Who is this professor named Utku?\n",
            "ANSWER:\n",
            "Utku Pamuksuz, PhD, is an Associate Clinical Professor and Co-Founder of Inference Analytics. He specializes in applied mathematics, machine/deep learning, responsible and generative AI, and has contributed to various analytics journals. He has been a faculty member at the University of Chicago since 2018, teaching subjects like data mining, machine learning, and AI-data science for leaders.\n",
            "\n",
            "SOURCES:\n",
            "- 007_instructors-staff.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 16: Are transcripts required? If yes, which one?\n",
            "ANSWER:\n",
            "Yes, transcripts are required for the application process. Initially, one unofficial transcript from each university you attended must be uploaded within the application. If you are offered admission, one official transcript for each university you attended will be required at least one month prior to matriculation.\n",
            "\n",
            "SOURCES:\n",
            "- 008_faqs.md\n",
            "- 004_how-to-apply.md\n",
            "- 010_online-program.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 17: Where do i send my e-transcript?\n",
            "ANSWER:\n",
            "You should send your e-transcript to applieddatascience-admissions@uchicago.edu. If your institution cannot send your documents electronically, they can mail your transcripts to: The University of Chicago, Attention: MS in Applied Data Science Admissions, 455 N Cityfront Plaza Dr., Suite 950, Chicago, Illinois 60611.\n",
            "\n",
            "SOURCES:\n",
            "- 008_faqs.md\n",
            "- 004_how-to-apply.md\n",
            "- 005_events-deadlines.md\n",
            "- 011_tuition-fees-aid.md\n",
            "- 002_capstone-projects.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY 18: Do I need to send a Portfolio?\n",
            "ANSWER:\n",
            "The provided documents do not mention a requirement to send a portfolio for the application process. They mention that you need to submit a candidate statement, resume/CV, letters of recommendation, and transcripts from all previous colleges and universities attended.\n",
            "\n",
            "SOURCES:\n",
            "- 010_online-program.md\n",
            "- 004_how-to-apply.md\n",
            "- 008_faqs.md\n",
            "- 007_instructors-staff.md\n",
            "- 002_capstone-projects.md\n",
            "- 001_in-person-program.md\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"TEST RESULTS:\\n\")\n",
        "for i, query in enumerate(test_queries, 1):\n",
        "    result = rag_chain_with_sources.invoke(query)\n",
        "\n",
        "    print(f\"QUERY {i}: {query}\")\n",
        "    print(f\"ANSWER:\\n{result['answer']}\\n\")\n",
        "\n",
        "    seen = set()\n",
        "    unique_urls = []\n",
        "    for doc in result[\"context\"]:\n",
        "        source = doc.metadata.get(\"source\", \"Unknown\")\n",
        "        if source not in seen:\n",
        "            seen.add(source)\n",
        "            unique_urls.append(source)\n",
        "\n",
        "    if unique_urls:\n",
        "        print(\"SOURCES:\")\n",
        "        for src in unique_urls:\n",
        "            print(f\"- {src}\")\n",
        "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XthpnzYXWlT4"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
